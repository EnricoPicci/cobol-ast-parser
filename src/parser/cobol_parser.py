"""COBOL parser wrapper using ANTLR4.

This module provides a high-level interface to the ANTLR4-generated
COBOL parser. It handles:
- Lexer and parser instantiation
- Error handling and reporting
- Parse tree generation
"""

from typing import Optional, List, Any
from dataclasses import dataclass, field
from pathlib import Path
import sys


class ParseError(Exception):
    """Error during COBOL parsing."""

    def __init__(self, message: str, line: int = 0, column: int = 0):
        self.line = line
        self.column = column
        super().__init__(f"Line {line}:{column} - {message}")


@dataclass
class ParseErrorInfo:
    """Information about a parse error."""

    message: str
    line: int
    column: int
    offending_symbol: Optional[str] = None


class CobolErrorListener:
    """Custom error listener for COBOL parsing."""

    def __init__(self):
        self.errors: List[ParseErrorInfo] = []

    def syntaxError(
        self,
        recognizer,
        offendingSymbol,
        line: int,
        column: int,
        msg: str,
        e,
    ):
        """Record a syntax error."""
        symbol_text = str(offendingSymbol) if offendingSymbol else None
        self.errors.append(
            ParseErrorInfo(
                message=msg,
                line=line,
                column=column,
                offending_symbol=symbol_text,
            )
        )

    def reportAmbiguity(self, *args, **kwargs):
        """Handle ambiguity reports (ignored)."""
        pass

    def reportAttemptingFullContext(self, *args, **kwargs):
        """Handle full context attempts (ignored)."""
        pass

    def reportContextSensitivity(self, *args, **kwargs):
        """Handle context sensitivity reports (ignored)."""
        pass

    def has_errors(self) -> bool:
        """Check if any errors were recorded."""
        return len(self.errors) > 0


class CobolParser:
    """High-level COBOL parser interface.

    This class wraps the ANTLR4-generated parser to provide a cleaner
    interface for parsing COBOL source code.
    """

    def __init__(self, use_generated: bool = True):
        """Initialize the COBOL parser.

        Args:
            use_generated: Whether to use ANTLR4-generated parser (requires generated files)
        """
        self.use_generated = use_generated
        self._parser = None
        self._lexer = None
        self._error_listener = None

        if use_generated:
            self._import_generated_parser()

    def _import_generated_parser(self):
        """Import the ANTLR4-generated parser classes."""
        try:
            # Try to import ANTLR4 runtime
            from antlr4 import CommonTokenStream, InputStream

            # Try to import generated parser files
            # These would be generated by running ANTLR4 on the grammar
            try:
                from .generated.Cobol85Lexer import Cobol85Lexer
                from .generated.Cobol85Parser import Cobol85Parser

                self._lexer_class = Cobol85Lexer
                self._parser_class = Cobol85Parser
                self._antlr_available = True
            except ImportError:
                # Generated files not yet created
                self._antlr_available = False

        except ImportError:
            # ANTLR4 runtime not installed
            self._antlr_available = False

    def parse(self, source: str) -> Any:
        """Parse COBOL source code.

        Args:
            source: COBOL source code string

        Returns:
            Parse tree (StartRuleContext) if using ANTLR4,
            or a simplified representation otherwise

        Raises:
            ParseError: If parsing fails
        """
        if (
            self.use_generated
            and hasattr(self, "_antlr_available")
            and self._antlr_available
        ):
            return self._parse_with_antlr(source)
        else:
            return self._parse_simplified(source)

    def _parse_with_antlr(self, source: str) -> Any:
        """Parse using ANTLR4-generated parser."""
        from antlr4 import CommonTokenStream, InputStream

        # Create input stream
        input_stream = InputStream(source)

        # Create lexer
        lexer = self._lexer_class(input_stream)
        lexer.removeErrorListeners()
        self._error_listener = CobolErrorListener()
        lexer.addErrorListener(self._error_listener)

        # Create token stream
        token_stream = CommonTokenStream(lexer)

        # Create parser
        parser = self._parser_class(token_stream)
        parser.removeErrorListeners()
        parser.addErrorListener(self._error_listener)

        # Parse starting from the start rule
        tree = parser.startRule()

        # Check for errors
        if self._error_listener.has_errors():
            first_error = self._error_listener.errors[0]
            raise ParseError(
                first_error.message,
                first_error.line,
                first_error.column,
            )

        return tree

    def _parse_simplified(self, source: str) -> "SimplifiedParseTree":
        """Parse using a simplified regex-based parser.

        This is a fallback when ANTLR4 is not available.
        It provides basic structure extraction.
        """
        return SimplifiedCobolParser().parse(source)

    def get_errors(self) -> List[ParseErrorInfo]:
        """Get list of parse errors.

        Returns:
            List of ParseErrorInfo objects
        """
        if self._error_listener:
            return self._error_listener.errors
        return []

    def parse_file(self, filepath: Path) -> Any:
        """Parse a COBOL file.

        Args:
            filepath: Path to the COBOL file

        Returns:
            Parse tree

        Raises:
            ParseError: If parsing fails
            FileNotFoundError: If file doesn't exist
        """
        source = filepath.read_text(encoding="utf-8", errors="replace")
        return self.parse(source)


@dataclass
class SimplifiedParseTree:
    """Simplified parse tree for use without ANTLR4."""

    program_name: str = ""
    identification_division: dict = field(default_factory=dict)
    environment_division: dict = field(default_factory=dict)
    data_division: "SimplifiedDataDivision" = field(
        default_factory=lambda: SimplifiedDataDivision()
    )
    procedure_division: "SimplifiedProcedureDivision" = field(
        default_factory=lambda: SimplifiedProcedureDivision()
    )
    source_lines: List[str] = field(default_factory=list)


@dataclass
class SimplifiedDataDivision:
    """Simplified data division representation."""

    working_storage: List["SimplifiedDataItem"] = field(default_factory=list)
    file_section: List["SimplifiedDataItem"] = field(default_factory=list)
    linkage_section: List["SimplifiedDataItem"] = field(default_factory=list)
    local_storage: List["SimplifiedDataItem"] = field(default_factory=list)


@dataclass
class SimplifiedDataItem:
    """Simplified data item representation."""

    level: int
    name: str
    picture: Optional[str] = None
    redefines: Optional[str] = None
    occurs: Optional[int] = None
    value: Optional[str] = None
    line_number: int = 0
    is_filler: bool = False


@dataclass
class SimplifiedProcedureDivision:
    """Simplified procedure division representation.

    Attributes:
        sections: List of sections in the procedure division.
        paragraphs: List of top-level paragraphs (not inside any section).
        orphan_statements: Statements that appear before any paragraph or section
            in the PROCEDURE DIVISION. These are typically initialization statements.
    """

    sections: List["SimplifiedSection"] = field(default_factory=list)
    paragraphs: List["SimplifiedParagraph"] = field(default_factory=list)
    orphan_statements: List["SimplifiedStatement"] = field(default_factory=list)


@dataclass
class SimplifiedSection:
    """Simplified section representation."""

    name: str
    paragraphs: List["SimplifiedParagraph"] = field(default_factory=list)
    statements: List["SimplifiedStatement"] = field(default_factory=list)
    line_number: int = 0


@dataclass
class SimplifiedParagraph:
    """Simplified paragraph representation."""

    name: str
    statements: List["SimplifiedStatement"] = field(default_factory=list)
    line_number: int = 0


@dataclass
class SimplifiedStatement:
    """Simplified statement representation."""

    statement_type: str
    text: str
    targets: List[str] = field(default_factory=list)  # Variables modified
    sources: List[str] = field(default_factory=list)  # Variables read
    line_number: int = 0


class SimplifiedCobolParser:
    """Simplified COBOL parser using regex patterns.

    This parser provides basic structure extraction without requiring
    ANTLR4. It's useful for testing and environments where ANTLR4
    cannot be installed.
    """

    import re

    # COBOL keywords that should not be captured as variable names
    COBOL_KEYWORDS = {
        # Data movement
        "MOVE",
        "TO",
        "FROM",
        "CORRESPONDING",
        "CORR",
        # Arithmetic
        "ADD",
        "SUBTRACT",
        "MULTIPLY",
        "DIVIDE",
        "COMPUTE",
        "GIVING",
        "REMAINDER",
        "ROUNDED",
        "BY",
        "INTO",
        # Control flow
        "PERFORM",
        "VARYING",
        "UNTIL",
        "TIMES",
        "THRU",
        "THROUGH",
        "IF",
        "ELSE",
        "END-IF",
        "THEN",
        "NOT",
        "AND",
        "OR",
        "EVALUATE",
        "WHEN",
        "OTHER",
        "END-EVALUATE",
        "GO",
        "GOTO",
        # I/O
        "DISPLAY",
        "ACCEPT",
        "READ",
        "WRITE",
        "REWRITE",
        "DELETE",
        "OPEN",
        "CLOSE",
        "START",
        "STOP",
        "RUN",
        # File handling
        "INPUT",
        "OUTPUT",
        "I-O",
        "EXTEND",
        # Procedure
        "CALL",
        "USING",
        "RETURNING",
        "ON",
        "SIZE",
        "ERROR",
        "OVERFLOW",
        "EXCEPTION",
        # String handling
        "STRING",
        "UNSTRING",
        "INSPECT",
        "TALLYING",
        "REPLACING",
        "CONVERTING",
        "DELIMITED",
        "POINTER",
        "COUNT",
        # Data manipulation
        "SET",
        "TRUE",
        "FALSE",
        "SEARCH",
        "ALL",
        "AT",
        "END",
        "INITIALIZE",
        "WITH",
        "FILLER",
        # Conditionals
        "NUMERIC",
        "ALPHABETIC",
        "ALPHABETIC-LOWER",
        "ALPHABETIC-UPPER",
        "POSITIVE",
        "NEGATIVE",
        "ZERO",
        "ZEROS",
        "ZEROES",
        "SPACE",
        "SPACES",
        "HIGH-VALUE",
        "HIGH-VALUES",
        "LOW-VALUE",
        "LOW-VALUES",
        "QUOTE",
        "QUOTES",
        # Misc
        "CONTINUE",
        "EXIT",
        "NEXT",
        "SENTENCE",
        "AFTER",
        "BEFORE",
        "INITIAL",
        "REFERENCE",
        "CONTENT",
        "VALUE",
    }

    # Division patterns
    IDENTIFICATION_DIVISION = re.compile(
        r"IDENTIFICATION\s+DIVISION\s*\.", re.IGNORECASE
    )
    ENVIRONMENT_DIVISION = re.compile(r"ENVIRONMENT\s+DIVISION\s*\.", re.IGNORECASE)
    DATA_DIVISION = re.compile(r"DATA\s+DIVISION\s*\.", re.IGNORECASE)
    PROCEDURE_DIVISION = re.compile(r"PROCEDURE\s+DIVISION[^.]*\.", re.IGNORECASE)

    # Section patterns
    WORKING_STORAGE = re.compile(r"WORKING-STORAGE\s+SECTION\s*\.", re.IGNORECASE)
    FILE_SECTION = re.compile(r"FILE\s+SECTION\s*\.", re.IGNORECASE)
    LINKAGE_SECTION = re.compile(r"LINKAGE\s+SECTION\s*\.", re.IGNORECASE)
    LOCAL_STORAGE = re.compile(r"LOCAL-STORAGE\s+SECTION\s*\.", re.IGNORECASE)

    # Data item pattern - supports clauses in any order
    # COBOL allows: REDEFINES, PIC, OCCURS, VALUE, USAGE in various orders
    # Use [ \t]* instead of \s* at start to avoid matching across lines
    DATA_ITEM = re.compile(
        r"^[ \t]*(\d{1,2})\s+"  # Level number (only match horizontal whitespace at start)
        r"([A-Za-z0-9][-A-Za-z0-9]*)"  # Data name
        r"((?:\s+(?:"
        r"REDEFINES\s+[A-Za-z0-9][-A-Za-z0-9]*"  # REDEFINES clause
        r"|PIC(?:TURE)?\s+(?:IS\s+)?[^\s.]+"  # PICTURE clause
        r"|OCCURS\s+\d+(?:\s+TIMES)?"  # OCCURS clause (with optional TIMES)
        r"|VALUE\s+(?:IS\s+)?[^.]*?"  # VALUE clause
        r"|USAGE\s+(?:IS\s+)?[A-Za-z0-9-]+"  # USAGE clause
        r"|COMP(?:-[0-9])?"  # COMP shorthand
        r"|BINARY"  # BINARY
        r"|PACKED-DECIMAL"  # PACKED-DECIMAL
        r"|DISPLAY"  # DISPLAY
        r"))*)"  # End of clauses group
        r"\s*\.",
        re.IGNORECASE | re.MULTILINE,
    )

    # Program-ID pattern
    PROGRAM_ID = re.compile(
        r"PROGRAM-ID\s*\.\s*([A-Za-z0-9][-A-Za-z0-9]*)", re.IGNORECASE
    )

    # Section/Paragraph patterns in procedure division
    SECTION_HEADER = re.compile(
        r"^\s*([A-Za-z0-9][-A-Za-z0-9]*)\s+SECTION\s*\.", re.IGNORECASE | re.MULTILINE
    )
    PARAGRAPH_HEADER = re.compile(
        r"^\s*([A-Za-z0-9][-A-Za-z0-9]*)\s*\.\s*$", re.IGNORECASE | re.MULTILINE
    )

    # Statement patterns (for modification tracking)
    # MOVE pattern - only allow comma-separated targets to avoid multi-line issues
    # Use [ \t] instead of \s to avoid matching newlines in target list
    MOVE_STMT = re.compile(
        r"\bMOVE\s+(.+?)\s+TO\s+([A-Za-z0-9][-A-Za-z0-9]*(?:[ \t]*\([^)]+\))?(?:[ \t]*,[ \t]*[A-Za-z0-9][-A-Za-z0-9]*(?:[ \t]*\([^)]+\))?)*)[ \t]*[.\n]",
        re.IGNORECASE,
    )
    COMPUTE_STMT = re.compile(
        r"\bCOMPUTE\s+([A-Za-z0-9][-A-Za-z0-9]*(?:\s*\([^)]+\))?)\s*=",
        re.IGNORECASE,
    )
    ADD_STMT = re.compile(
        r"\bADD\s+(.+?)\s+TO\s+([A-Za-z0-9][-A-Za-z0-9]*(?:\s*\([^)]+\))?)",
        re.IGNORECASE,
    )
    SUBTRACT_STMT = re.compile(
        r"\bSUBTRACT\s+(.+?)\s+FROM\s+([A-Za-z0-9][-A-Za-z0-9]*(?:\s*\([^)]+\))?)",
        re.IGNORECASE,
    )
    MULTIPLY_STMT = re.compile(
        r"\bMULTIPLY\s+(.+?)\s+BY\s+([A-Za-z0-9][-A-Za-z0-9]*(?:\s*\([^)]+\))?)",
        re.IGNORECASE,
    )
    DIVIDE_STMT = re.compile(
        r"\bDIVIDE\s+(.+?)\s+(?:INTO|BY)\s+([A-Za-z0-9][-A-Za-z0-9]*(?:\s*\([^)]+\))?)",
        re.IGNORECASE,
    )
    ACCEPT_STMT = re.compile(
        r"\bACCEPT\s+([A-Za-z0-9][-A-Za-z0-9]*(?:\s*\([^)]+\))?)",
        re.IGNORECASE,
    )
    READ_STMT = re.compile(
        r"\bREAD\s+([A-Za-z0-9][-A-Za-z0-9]*)\s+INTO\s+([A-Za-z0-9][-A-Za-z0-9]*(?:\s*\([^)]+\))?)",
        re.IGNORECASE,
    )
    # INITIALIZE pattern - only allow comma-separated targets
    INITIALIZE_STMT = re.compile(
        r"\bINITIALIZE\s+([A-Za-z0-9][-A-Za-z0-9]*(?:[ \t]*\([^)]+\))?(?:[ \t]*,[ \t]*[A-Za-z0-9][-A-Za-z0-9]*(?:[ \t]*\([^)]+\))?)*)",
        re.IGNORECASE,
    )
    SET_STMT = re.compile(
        r"\bSET\s+([A-Za-z0-9][-A-Za-z0-9]*(?:\s*\([^)]+\))?)\s+TO\s+",
        re.IGNORECASE,
    )
    STRING_STMT = re.compile(
        r"\bSTRING\s+.+?\s+INTO\s+([A-Za-z0-9][-A-Za-z0-9]*(?:\s*\([^)]+\))?)",
        re.IGNORECASE | re.DOTALL,
    )
    # UNSTRING pattern - only allow comma-separated targets
    UNSTRING_STMT = re.compile(
        r"\bUNSTRING\s+.+?\s+INTO\s+([A-Za-z0-9][-A-Za-z0-9]*(?:[ \t]*\([^)]+\))?(?:[ \t]*,[ \t]*[A-Za-z0-9][-A-Za-z0-9]*(?:[ \t]*\([^)]+\))?)*)",
        re.IGNORECASE | re.DOTALL,
    )
    INSPECT_STMT = re.compile(
        r"\bINSPECT\s+([A-Za-z0-9][-A-Za-z0-9]*(?:\s*\([^)]+\))?)\s+(?:TALLYING|REPLACING|CONVERTING)",
        re.IGNORECASE,
    )

    def parse(self, source: str) -> SimplifiedParseTree:
        """Parse COBOL source into a simplified parse tree.

        Args:
            source: COBOL source code

        Returns:
            SimplifiedParseTree object
        """
        tree = SimplifiedParseTree()
        tree.source_lines = source.splitlines()

        # Extract program name
        match = self.PROGRAM_ID.search(source)
        if match:
            tree.program_name = match.group(1).upper()

        # Find division boundaries
        divisions = self._find_division_boundaries(source)

        # Parse data division
        if "data" in divisions:
            data_start, data_end = divisions["data"]
            data_source = source[data_start:data_end]
            tree.data_division = self._parse_data_division(
                data_source, data_start, tree.source_lines
            )

        # Parse procedure division
        if "procedure" in divisions:
            proc_start, proc_end = divisions["procedure"]
            proc_source = source[proc_start:proc_end]
            tree.procedure_division = self._parse_procedure_division(
                proc_source, proc_start, tree.source_lines
            )

        return tree

    def _find_division_boundaries(self, source: str) -> dict:
        """Find the start and end positions of each division."""
        divisions = {}
        source_upper = source.upper()

        # Find all division starts
        div_positions = []

        for pattern, name in [
            (self.IDENTIFICATION_DIVISION, "identification"),
            (self.ENVIRONMENT_DIVISION, "environment"),
            (self.DATA_DIVISION, "data"),
            (self.PROCEDURE_DIVISION, "procedure"),
        ]:
            match = pattern.search(source)
            if match:
                div_positions.append((match.start(), name))

        # Sort by position
        div_positions.sort(key=lambda x: x[0])

        # Calculate boundaries
        for i, (pos, name) in enumerate(div_positions):
            if i + 1 < len(div_positions):
                end = div_positions[i + 1][0]
            else:
                end = len(source)
            divisions[name] = (pos, end)

        return divisions

    def _parse_data_division(
        self, source: str, offset: int, all_lines: List[str]
    ) -> SimplifiedDataDivision:
        """Parse the DATA DIVISION."""
        data_div = SimplifiedDataDivision()

        # Find section boundaries within data division
        sections = {
            "working_storage": (self.WORKING_STORAGE, data_div.working_storage),
            "file_section": (self.FILE_SECTION, data_div.file_section),
            "linkage_section": (self.LINKAGE_SECTION, data_div.linkage_section),
            "local_storage": (self.LOCAL_STORAGE, data_div.local_storage),
        }

        section_positions = []
        for name, (pattern, _) in sections.items():
            match = pattern.search(source)
            if match:
                section_positions.append((match.end(), name))

        section_positions.sort(key=lambda x: x[0])

        # Parse each section
        for i, (start_pos, section_name) in enumerate(section_positions):
            if i + 1 < len(section_positions):
                end_pos = section_positions[i + 1][0]
            else:
                end_pos = len(source)

            section_source = source[start_pos:end_pos]
            items = self._parse_data_items(
                section_source, offset + start_pos, all_lines
            )
            sections[section_name][1].extend(items)

        return data_div

    # Helper patterns for extracting individual clauses
    REDEFINES_EXTRACT = re.compile(
        r"\bREDEFINES\s+([A-Za-z0-9][-A-Za-z0-9]*)", re.IGNORECASE
    )
    PICTURE_EXTRACT = re.compile(
        r"\bPIC(?:TURE)?\s+(?:IS\s+)?([^\s.]+)", re.IGNORECASE
    )
    OCCURS_EXTRACT = re.compile(
        r"\bOCCURS\s+(\d+)(?:\s+TIMES)?", re.IGNORECASE
    )
    VALUE_EXTRACT = re.compile(
        r"\bVALUE\s+(?:IS\s+)?([^.]*?)(?=\s+(?:REDEFINES|PIC|OCCURS|USAGE|COMP|BINARY|PACKED|DISPLAY)\b|\s*$)",
        re.IGNORECASE
    )

    def _parse_data_items(
        self, source: str, offset: int, all_lines: List[str]
    ) -> List[SimplifiedDataItem]:
        """Parse data items from a section."""
        items = []
        filler_counter = 0

        for match in self.DATA_ITEM.finditer(source):
            level = int(match.group(1))
            name = match.group(2).upper()

            # Handle FILLER items - give them unique internal names
            is_filler = False
            if name == "FILLER":
                filler_counter += 1
                name = f"FILLER${filler_counter}"
                is_filler = True

            # Extract clauses from the captured clause group
            clauses = match.group(3) if match.group(3) else ""

            # Extract individual clause values
            redefines_match = self.REDEFINES_EXTRACT.search(clauses)
            redefines = redefines_match.group(1).upper() if redefines_match else None

            picture_match = self.PICTURE_EXTRACT.search(clauses)
            picture = picture_match.group(1) if picture_match else None

            occurs_match = self.OCCURS_EXTRACT.search(clauses)
            occurs = int(occurs_match.group(1)) if occurs_match else None

            value_match = self.VALUE_EXTRACT.search(clauses)
            value = value_match.group(1).strip() if value_match else None

            # Calculate line number using absolute position in full source
            pos = offset + match.start()
            line_num = self._get_line_number_at_offset(all_lines, pos)

            items.append(
                SimplifiedDataItem(
                    level=level,
                    name=name,
                    picture=picture,
                    redefines=redefines,
                    occurs=occurs,
                    value=value,
                    line_number=line_num,
                    is_filler=is_filler,
                )
            )

        return items

    def _parse_procedure_division(
        self, source: str, offset: int, all_lines: List[str]
    ) -> SimplifiedProcedureDivision:
        """Parse the PROCEDURE DIVISION."""
        proc_div = SimplifiedProcedureDivision()

        # Find sections and paragraphs
        section_matches = list(self.SECTION_HEADER.finditer(source))
        paragraph_matches = list(self.PARAGRAPH_HEADER.finditer(source))

        # Filter paragraph matches that are actually section headers
        section_names = {m.group(1).upper() for m in section_matches}
        paragraph_matches = [
            m for m in paragraph_matches if m.group(1).upper() not in section_names
        ]

        if section_matches:
            # Parse orphan statements before first section
            first_section_start = section_matches[0].start()
            if first_section_start > 0:
                orphan_source = source[:first_section_start]
                proc_div.orphan_statements = self._extract_statements(
                    orphan_source, offset, all_lines
                )

            # Parse with sections
            for i, match in enumerate(section_matches):
                section_name = match.group(1).upper()
                section_start = match.end()

                if i + 1 < len(section_matches):
                    section_end = section_matches[i + 1].start()
                else:
                    section_end = len(source)

                section_source = source[section_start:section_end]
                section = self._parse_section(
                    section_name, section_source, offset + section_start, all_lines
                )
                proc_div.sections.append(section)
        else:
            # No sections, just paragraphs
            # Parse orphan statements before first paragraph
            if paragraph_matches:
                first_para_start = paragraph_matches[0].start()
                if first_para_start > 0:
                    orphan_source = source[:first_para_start]
                    proc_div.orphan_statements = self._extract_statements(
                        orphan_source, offset, all_lines
                    )

            for i, match in enumerate(paragraph_matches):
                para_name = match.group(1).upper()
                para_start = match.end()

                if i + 1 < len(paragraph_matches):
                    para_end = paragraph_matches[i + 1].start()
                else:
                    para_end = len(source)

                para_source = source[para_start:para_end]
                paragraph = self._parse_paragraph(
                    para_name, para_source, offset + para_start, all_lines
                )
                proc_div.paragraphs.append(paragraph)

        return proc_div

    def _parse_section(
        self, name: str, source: str, offset: int, all_lines: List[str]
    ) -> SimplifiedSection:
        """Parse a section."""
        section = SimplifiedSection(name=name)

        # Find paragraphs within section
        paragraph_matches = list(self.PARAGRAPH_HEADER.finditer(source))

        if paragraph_matches:
            # Parse statements before first paragraph
            pre_para_source = source[: paragraph_matches[0].start()]
            section.statements = self._extract_statements(
                pre_para_source, offset, all_lines
            )

            # Parse each paragraph
            for i, match in enumerate(paragraph_matches):
                para_name = match.group(1).upper()
                para_start = match.end()

                if i + 1 < len(paragraph_matches):
                    para_end = paragraph_matches[i + 1].start()
                else:
                    para_end = len(source)

                para_source = source[para_start:para_end]
                paragraph = self._parse_paragraph(
                    para_name, para_source, offset + para_start, all_lines
                )
                section.paragraphs.append(paragraph)
        else:
            # No paragraphs, just statements
            section.statements = self._extract_statements(source, offset, all_lines)

        return section

    def _parse_paragraph(
        self, name: str, source: str, offset: int, all_lines: List[str]
    ) -> SimplifiedParagraph:
        """Parse a paragraph."""
        paragraph = SimplifiedParagraph(name=name)
        paragraph.statements = self._extract_statements(source, offset, all_lines)
        return paragraph

    def _get_line_number_at_offset(self, all_lines: List[str], char_offset: int) -> int:
        """Calculate the 1-based line number for a character offset in the original source.

        Args:
            all_lines: All source lines from the original file
            char_offset: Character offset from the beginning of the source

        Returns:
            1-based line number
        """
        current_pos = 0
        for line_num, line in enumerate(all_lines, start=1):
            # Each line includes its newline character in the offset calculation
            line_length = len(line) + 1  # +1 for newline
            if current_pos + line_length > char_offset:
                return line_num
            current_pos += line_length
        # If we reach here, return the last line
        return len(all_lines)

    def _extract_statements(
        self, source: str, offset: int, all_lines: List[str]
    ) -> List[SimplifiedStatement]:
        """Extract modifying statements from source."""
        statements = []

        # Statement patterns and their types
        patterns = [
            (self.MOVE_STMT, "MOVE", self._extract_move_targets),
            (self.COMPUTE_STMT, "COMPUTE", self._extract_single_target),
            (self.ADD_STMT, "ADD", self._extract_arithmetic_targets),
            (self.SUBTRACT_STMT, "SUBTRACT", self._extract_arithmetic_targets),
            (self.MULTIPLY_STMT, "MULTIPLY", self._extract_arithmetic_targets),
            (self.DIVIDE_STMT, "DIVIDE", self._extract_arithmetic_targets),
            (self.ACCEPT_STMT, "ACCEPT", self._extract_single_target),
            (self.READ_STMT, "READ", self._extract_read_targets),
            (self.INITIALIZE_STMT, "INITIALIZE", self._extract_multi_targets),
            (self.SET_STMT, "SET", self._extract_single_target),
            (self.STRING_STMT, "STRING", self._extract_single_target),
            (self.UNSTRING_STMT, "UNSTRING", self._extract_multi_targets),
            (self.INSPECT_STMT, "INSPECT", self._extract_single_target),
        ]

        for pattern, stmt_type, extractor in patterns:
            for match in pattern.finditer(source):
                targets = extractor(match)
                # Calculate actual line number using offset from original source
                char_pos = offset + match.start()
                line_num = self._get_line_number_at_offset(all_lines, char_pos)

                statements.append(
                    SimplifiedStatement(
                        statement_type=stmt_type,
                        text=match.group(0).strip(),
                        targets=targets,
                        line_number=line_num,
                    )
                )

        return statements

    def _extract_move_targets(self, match) -> List[str]:
        """Extract targets from MOVE statement."""
        targets_str = match.group(2)
        return self._split_variable_list(targets_str)

    def _extract_single_target(self, match) -> List[str]:
        """Extract single target from statement."""
        target = match.group(1).strip()
        # Remove subscripts
        target = self._remove_subscript(target)
        return [target.upper()]

    def _extract_arithmetic_targets(self, match) -> List[str]:
        """Extract targets from arithmetic statements."""
        target = match.group(2).strip()
        target = self._remove_subscript(target)
        return [target.upper()]

    def _extract_read_targets(self, match) -> List[str]:
        """Extract targets from READ statement."""
        target = match.group(2).strip()
        target = self._remove_subscript(target)
        return [target.upper()]

    def _extract_multi_targets(self, match) -> List[str]:
        """Extract multiple targets from statement."""
        targets_str = match.group(1)
        return self._split_variable_list(targets_str)

    def _split_variable_list(self, text: str) -> List[str]:
        """Split a list of variable names, filtering out COBOL keywords."""
        import re

        # Split on commas and whitespace, filter empties
        parts = re.split(r"[,\s]+", text)
        results = []
        for part in parts:
            part = part.strip()
            if part and part[0].isalpha():
                part = self._remove_subscript(part)
                upper_part = part.upper()
                # Filter out COBOL keywords
                if upper_part not in self.COBOL_KEYWORDS:
                    results.append(upper_part)
        return results

    def _remove_subscript(self, text: str) -> str:
        """Remove subscript from variable name."""
        paren_pos = text.find("(")
        if paren_pos >= 0:
            return text[:paren_pos].strip()
        return text.strip()
